{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3022692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict \n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import  accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import time\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2401e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/58961768/set-torch-backends-cudnn-benchmark-true-or-not\n",
    "def set_seed(seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "set_seed(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c8c6b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "        # self.mx_len = 0\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        # for word in sentence.split(' '):\n",
    "        #     self.addWord(word)\n",
    "        for x in sentence: \n",
    "            self.addWord(x)\n",
    "\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2f7495e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 40000 dates\n",
      "('friday 1791 2 09', '1791-09-02')\n",
      "Max sentence length : 27, 10\n",
      "('friday 1791 2 09', '1791-09-02')\n",
      "36 13\n"
     ]
    }
   ],
   "source": [
    "def fill_buffer(buffer, path): \n",
    "    with open(path, 'r', encoding = 'latin-1') as file:\n",
    "        for rows in file:\n",
    "            a, b = (rows.split(\", \"))\n",
    "            a = a[1:-1]  # removing ''\n",
    "            b = b[1:-2]  # removing ''\\n\n",
    "            buffer.append((a, b))\n",
    "    \n",
    "    print(\"Got {} dates\".format(len(buffer)))\n",
    "    return buffer\n",
    "\n",
    "\n",
    "buffer = []\n",
    "buffer = fill_buffer(buffer,  path = \"Assignment4aDataset.txt\" )\n",
    "print(buffer[5])\n",
    "\n",
    "def preprocess(buffer):\n",
    "    mx_len1, mx_len2 = 0, 0\n",
    "    date_lang = Lang(\"date\")\n",
    "    label_lang = Lang(\"label\")\n",
    "    \n",
    "    \n",
    "    for i, (date, label) in enumerate(buffer):\n",
    "\n",
    "        # string \n",
    "        date_lang.addSentence(date)\n",
    "        label_lang.addSentence(label)\n",
    "\n",
    "        # # split \n",
    "        # date = date.split(\" \")\n",
    "        # label = label.split(\" \")\n",
    "        \n",
    "        mx_len1 = max(mx_len1, len(date))\n",
    "        mx_len2 = max(mx_len2, len(label))\n",
    "\n",
    "        buffer[i] = (date, label)\n",
    "         \n",
    "    print(\"Max sentence length : {}, {}\".format(mx_len1, mx_len2))\n",
    "    return buffer, date_lang, label_lang\n",
    "    \n",
    "buffer, date_lang, label_lang = preprocess(buffer)\n",
    "# get_data_stat(embedding_dict, buffer, dtype = \"str\")\n",
    "print(buffer[5])\n",
    "\n",
    "print(date_lang.n_words, label_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d04430c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( sorted(label_lang.word2count.keys())  )\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aacc875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    # return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    return [lang.word2index[w] for w in sentence]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(date_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(label_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "# print( buffer[5], \"\\n\", tensorsFromPair(buffer[5]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ec8e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d8e79d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 28 #37  #5 # encoder's max date format + eos\n",
    "\n",
    "# hidden_size, label_lang.n_words, dropout_p=0.1\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "\n",
    "        # s(t-1) concat with h(j) \n",
    "        self.W1 = nn.Linear( self.hidden_size , self.hidden_size ) \n",
    "        self.W2 = nn.Linear( self.hidden_size, self.hidden_size )\n",
    "        self.V = nn.Linear( self.hidden_size , 1 ) \n",
    "\n",
    "        self.gru = nn.GRU( 2 * self.hidden_size, self.hidden_size )\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "\n",
    "\n",
    "    # torch.Size([1, 1]) torch.Size([1, 1, 256]) torch.Size([4, 256])\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # print(input.shape, hidden.shape, encoder_outputs.shape)\n",
    "        embedded = self.embedding(input) # .view(1, 1, -1)\n",
    "        # print(\"embed: \", embedded.shape) # (1, 1, 256) ???? \n",
    "        # embedded = self.dropout(embedded) \n",
    "        \n",
    "        # (4 * 256)\n",
    "        X = torch.tanh(self.W1(hidden) + self.W2(encoder_outputs))\n",
    "        wts = torch.softmax( self.V(X).view(-1), dim = 0 )\n",
    "        wts = wts.unsqueeze(1)\n",
    "        # print(\"wt: \", wts.shape)\n",
    "        # return \n",
    "\n",
    "        C_j = torch.sum(wts * encoder_outputs, dim = 0)\n",
    "        # print(\"C_j: \", C_j.shape) # 256\n",
    "        # return \n",
    " \n",
    "        input = torch.cat([C_j, embedded.view(-1)]).view(1, 1, -1)\n",
    "        output, hidden_gru = self.gru(input, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        # print(output.shape, hidden_gru.shape)\n",
    "        return output, hidden_gru, wts\n",
    "\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b2a557e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "wts = torch.randn(4, 1)\n",
    "en_out = torch.randn(4, 256)\n",
    "\n",
    "print( torch.sum(wts * en_out, dim = 0).shape )\n",
    "\n",
    "\n",
    "gru = nn.GRU(2 * 256, 256)\n",
    "print(wts.squeeze(1).shape)\n",
    "# output, hidden = gru( torch.randn((1, 512)), torch.zeros((1, 256)) )\n",
    "# print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7d6d67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer,\\\n",
    "          decoder_optimizer, criterion, max_length = MAX_LENGTH, teacher_forcing_ratio = 0.5):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # print(\"encoder, \", input_length) \n",
    "    \n",
    "    # for each word \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        # print(encoder_output.shape) # (1, 1, 256)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0] # \n",
    "    \n",
    "    \n",
    "    # print(encoder_outputs.shape) #  (4, 256)\n",
    "    \n",
    "    ###################################################################\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    result = []\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    decoder_attentions = []\n",
    "\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            result.append(topi.item())\n",
    "            # print(decoder_attention.squeeze(1).shape)\n",
    "            decoder_attentions.append( decoder_attention.detach().squeeze(1).cpu().numpy() )\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    return loss, result, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4881ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder1, attn_decoder1, train_buffer\n",
    "\n",
    "def trainIters(encoder, decoder, buffer, learning_rate=0.001):\n",
    "    n_iters = len(buffer)\n",
    "    \n",
    "    print(n_iters)\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(buffer[i]) for i in range(n_iters) ]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    batch_loss = 0 \n",
    "    batch_size = 100\n",
    "    total_loss = 0\n",
    "    epoch_size = 500 \n",
    "\n",
    "    for iter in range(1, n_iters + 1):  \n",
    "        training_pair = training_pairs[(iter - 1)]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss, _, _ = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "        batch_loss += loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if iter % epoch_size == 0: \n",
    "            print(\"{} {:.4f}\".format(iter // epoch_size, total_loss / (target_tensor.shape[0] * epoch_size) )) # , end = \" \") \n",
    "            total_loss = 0\n",
    "\n",
    "\n",
    "        if iter % batch_size == 0: \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            batch_loss /= batch_size\n",
    "            batch_loss.backward()\n",
    "\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "            # print(\"\\r {} {:.4f}\".format(iter, loss.item()/target_tensor.shape[0] ), end = \" \") #################\n",
    "            batch_loss = 0\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4def718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder1 = EncoderRNN(date_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size = hidden_size, \\\n",
    "    output_size = label_lang.n_words, dropout_p=0.1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d12b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(buffer)\n",
    "\n",
    "upto = int(0.7 * len(buffer))\n",
    "train_buffer = buffer[:upto]\n",
    "\n",
    "test_buffer = buffer[upto : ]\n",
    "\n",
    "# trainIters(encoder1, attn_decoder1, train_buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e22cf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder1, attn_decoder1, train_buffer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points, iter):\n",
    "    points = np.stack([x for x in points])\n",
    "    # print(points.shape)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(points)\n",
    "    plt.savefig(str(iter))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def testIters(encoder : nn.Module, decoder, buffer, learning_rate=0.001):\n",
    "    n_iters = len(buffer)\n",
    "\n",
    "    print(n_iters)\n",
    "\n",
    "    encoder.load_state_dict(torch.load(\"models/encoder1.pth\"))\n",
    "    decoder.load_state_dict(torch.load(\"models/decoder1.pth\"))\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(buffer[i]) for i in range(n_iters) ]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "\n",
    "    total_loss = 0\n",
    "    acc = 0\n",
    "    acc1 = 0 \n",
    "    epoch_size = 1000 \n",
    "\n",
    "    for iter in range(1, n_iters + 1):  \n",
    "        training_pair = training_pairs[(iter - 1) % len(training_pairs)]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        _, result, decoder_attentions = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion, teacher_forcing_ratio = 0)\n",
    "\n",
    "        # total_loss += loss.item()\n",
    "        result = torch.tensor(result)\n",
    "        print(\"\\r{} {}\".format(iter, len(result)), end = \" \")\n",
    "        sum = (result.view(-1) == target_tensor.cpu().view(-1)).sum()\n",
    "        if len(result) == 11 and sum == 11: \n",
    "            acc += 1\n",
    "        \n",
    "        acc1 += (sum / 11)\n",
    "\n",
    "        if iter % epoch_size == 0: \n",
    "            print(\"{} {:.4f} {:.4f}\".format(iter,  acc / iter , acc1 / iter) )  # , end = \" \") \n",
    "            showPlot(decoder_attentions, iter)\n",
    "\n",
    "\n",
    "\n",
    "# testIters(encoder1, attn_decoder1, test_buffer)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0bb7505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 10000 dates\n",
      "('3 november 2064', '2064-11-03')\n",
      "10000\n",
      "1000 11 1000 0.9680 0.9962\n",
      "(11, 28)\n",
      "1600 11 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-19b9e70cd8bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     output_size = label_lang.n_words, dropout_p=0.1).to(device)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtestIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-e167620980be>\u001b[0m in \u001b[0;36mtestIters\u001b[0;34m(encoder, decoder, buffer, learning_rate)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         _, result, decoder_attentions = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 41\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion, teacher_forcing_ratio = 0)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# total_loss += loss.item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-34d07bd3246e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mei\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         encoder_output, encoder_hidden = encoder(\n\u001b[0;32m---> 17\u001b[0;31m             input_tensor[ei], encoder_hidden)\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# print(encoder_output.shape) # (1, 1, 256)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-40ba97049ef4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 850\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    851\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_buffer = []\n",
    "test_buffer = fill_buffer(test_buffer,  path = \"Assignment4aTestDataset.txt\" )\n",
    "print(test_buffer[5])\n",
    "\n",
    "encoder2 = EncoderRNN(date_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder2 = AttnDecoderRNN(hidden_size = hidden_size, \\\n",
    "    output_size = label_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "testIters(encoder2, attn_decoder2, test_buffer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
